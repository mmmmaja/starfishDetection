{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Starfish Detection","text":""},{"location":"#project-layout","title":"Project layout","text":"<pre><code>\u251c\u2500\u2500 .github/                  # Github actions and dependabot\n\u2502   \u251c\u2500\u2500 dependabot.yaml\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 tests.yaml\n\u251c\u2500\u2500 configs/                  # Configuration files\n\u251c\u2500\u2500 data/                     # Data directory\n\u2502   \u251c\u2500\u2500 processed\n\u2502   \u2514\u2500\u2500 raw\n\u251c\u2500\u2500 dockerfiles/              # Dockerfiles\n\u2502   \u251c\u2500\u2500 api.Dockerfile\n\u2502   \u2514\u2500\u2500 train.Dockerfile\n\u251c\u2500\u2500 docs/                     # Documentation\n\u2502   \u251c\u2500\u2500 mkdocs.yml\n\u2502   \u2514\u2500\u2500 source/\n\u2502       \u2514\u2500\u2500 index.md\n\u251c\u2500\u2500 models/                   # Trained models\n\u251c\u2500\u2500 notebooks/                # Jupyter notebooks\n\u251c\u2500\u2500 reports/                  # Reports\n\u2502   \u2514\u2500\u2500 figures/\n\u251c\u2500\u2500 src/                      # Source code\n\u2502   \u251c\u2500\u2500 project_name/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 api.py\n\u2502   \u2502   \u251c\u2500\u2500 data.py\n\u2502   \u2502   \u251c\u2500\u2500 evaluate.py\n\u2502   \u2502   \u251c\u2500\u2500 models.py\n\u2502   \u2502   \u251c\u2500\u2500 train.py\n\u2502   \u2502   \u2514\u2500\u2500 visualize.py\n\u2514\u2500\u2500 tests/                    # Tests\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_api.py\n\u2502   \u251c\u2500\u2500 test_data.py\n\u2502   \u2514\u2500\u2500 test_model.py\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 pyproject.toml            # Python project file\n\u251c\u2500\u2500 README.md                 # Project README\n\u251c\u2500\u2500 requirements.txt          # Project requirements\n\u251c\u2500\u2500 requirements_dev.txt      # Development requirements\n\u2514\u2500\u2500 tasks.py                  # Project tasks\n</code></pre>"},{"location":"application/","title":"Application","text":"<p>Users can interact with our application using the backend or the frontend.</p>"},{"location":"application/#backend","title":"Backend","text":"<p>To obtain predictions on an image by communicating with the API directly, you can use a curl command. To use the PyTorch model for inference, run</p> <pre><code>curl -X 'POST' 'https://backend-638730968773.us-central1.run.app/inference/' -H 'accept: application/json' -H 'Content-Type: multipart/form-data' -F 'data=@PATH_TO_IMAGE;type=image/jpeg'\n</code></pre> <p>To use the ONNX model for inference, run</p> <pre><code>curl -X 'POST' 'https://backend-638730968773.us-central1.run.app/onnx-inference/' -H 'accept: application/json' -H 'Content-Type: multipart/form-data' -F 'data=@PATH_TO_IMAGE;type=image/jpeg'\n</code></pre>"},{"location":"application/#frontend","title":"Frontend","text":"<p>For a more user-friendly experience, you can access our frontend webpage at https://frontend-638730968773.us-central1.run.app.</p> <p>Follow these steps to get predictions on an image.</p> <ol> <li> <p>Click <code>Browse files</code>. app-image1</p> </li> <li> <p>Select your desired image.  app-image2</p> </li> <li> <p>You should then see the image you selected appear. app-image3</p> </li> <li> <p>Once the inference has finished, you will see boxes on your image around predicted starfish along with confidence scores. app-image4</p> </li> <li> <p>Below you will also see a histogram over the confidence scores for your image. app-image5</p> </li> <li> <p>Finally, you get a matrix of the bounding box coordinates in pixel coordinates.</p> </li> </ol>"},{"location":"code/","title":"Training","text":""},{"location":"code/#environment","title":"Environment","text":"<p>Create a dedicated environment to keep track of the packages for the project</p> <pre><code>conda create --name starfish-env python=3.11\nconda activate starfish-env\npip install -r requirements.txt\npip install -r requirements_dev.txt\npip install -e .\n</code></pre>"},{"location":"code/#data","title":"Data","text":"<p>Download the data for the project from our Google Cloud Bucket, which requires the Google Cloud SDK</p> <pre><code>invoke download-data\n</code></pre>"},{"location":"code/#train","title":"Train","text":"<p>Train with default arguments</p> <pre><code>train\n</code></pre> <p>Train with data downloaded from the bucket rather than accessing it directly from the cloud</p> <pre><code>train data.data_from_bucket=false\n</code></pre>"},{"location":"code/#profiling","title":"Profiling","text":"<p>Train with profiling</p> <pre><code>train profiling=True\n</code></pre> <p>Profile forward pass</p> <pre><code>invoke profile-forward-pass\n</code></pre>"},{"location":"code/#docker","title":"Docker","text":"<p>Build the training dockerfile into a Docker image</p> <pre><code>invoke build-train-image\n</code></pre> <p>Run a container spawned from the docker image</p> <pre><code>invoke run-train-image\n</code></pre> <p>Build an image for the backend and push it to the cloud</p> <pre><code>invoke backend-image-to-cloud\n</code></pre> <p>Build an image for the frontend and push it to the cloud</p> <pre><code>invoke frontend-image-to-cloud\n</code></pre> <p>Test a docker image locally</p> <pre><code>docker run --rm -p 8080:8080 -e \"PORT=8080\" IMAGE_NAME\n</code></pre> <p>Deploy the backend</p> <pre><code>invoke deploy-backend\n</code></pre> <p>Deploy the frontend</p> <pre><code>invoke deploy-frontend\n</code></pre>"},{"location":"code/#vertex-ai","title":"Vertex AI","text":"<p>Get the Docker image built from <code>train.dockerfile</code> in the Artifact Registry on Google Cloud, for example by creating a trigger and using the <code>cloudbuild.yaml</code> file. Then you can train a model using that Docker image through the Vertex AI service. This also automatically logs the training to Wandb if your API key has been stored as a secret in Google Cloud.</p> <pre><code>invoke train-vertex\n</code></pre>"},{"location":"code/#wandb","title":"Wandb","text":"<p>Login</p> <pre><code>wandb login\n</code></pre> <p>Hyperparameter sweep</p> <pre><code>invoke sweep\nwandb agent ENTITY/PROJECT_NAME/AGENT_ID\n</code></pre>"},{"location":"code/#deploy-application","title":"Deploy application","text":"<p>Deploy the application by running the backend and frontend Docker images in the Artifact Registry generated by the Cloud Build trigger and <code>cloudbuild.yaml</code>.</p> <pre><code>gcloud run deploy backend --image=us-central1-docker.pkg.dev/starfish-detection/frontend-backend/backend:latest --region=us-central1 --platform=managed --allow-unauthenticated --port=8080\ngcloud run deploy frontend --image=us-central1-docker.pkg.dev/starfish-detection/frontend-backend/frontend:latest --region=us-central1 --platform=managed --allow-unauthenticated --port=8080\n</code></pre>"},{"location":"code/#tests","title":"Tests","text":"<p>Run all tests and calculate coverage</p> <pre><code>invoke test\n</code></pre> <p>Run data tests</p> <pre><code>invoke test-data\n</code></pre> <p>Run model tests</p> <pre><code>invoke test-model\n</code></pre> <p>Load test</p> <pre><code>locust -f tests/performancetests/locustfile.py --headless --users 10 --spawn-rate 1 --run-time 1m --host https://backend-638730968773.us-central1.run.app\n</code></pre>"},{"location":"code/#documentation-site","title":"Documentation Site","text":"<p>Build site locally</p> <pre><code>mkdocs build\n</code></pre> <p>Deploy site to <code>gh-pages</code> branch</p> <pre><code>mkdocs gh-deploy\n</code></pre>"}]}